name: Run Full MLB DFS Pipeline

on:
  workflow_dispatch:
  schedule:
    - cron: '15 12 * * *'  # Runs daily at 12:15 UTC (~6:15 AM Central)

env:
  STRUCTURED_DIR: baseball/combined
  ARCHIVE_DIR: baseball/combined/archive
  RECAP_DIR: baseball/combined

jobs:
  run-pipeline:
    runs-on: ubuntu-latest
    steps:

      - name: ğŸ“¥ Checkout repo
        uses: actions/checkout@v3

      - name: ğŸ Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: ğŸ“¦ Install dependencies
        run: pip install -r requirements.txt

      - name: ğŸ•’ Set current date
        id: date
        run: echo "today=$(date -u +'%Y-%m-%d')" >> $GITHUB_OUTPUT

      - name: ğŸ§© Combine data sources
        run: python mlb_data_combiner/combine_data.py --date ${{ steps.date.outputs.today }}

      - name: ğŸ“Š Enhance with streak trends
        run: python mlb_data_analyzer/player_stats_analyzer.py

      - name: ğŸ“ Generate initial DFS article
        run: python mlb_baseball_article_generator/generate_dfs_article.py --date ${{ steps.date.outputs.today }}

      - name: â˜ï¸ Upload to S3
        run: |
          pip install awscli
          aws s3 cp baseball/combined s3://your-bucket-name/baseball/combined/ --recursive --exclude "*" --include "*.json"
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: us-east-1
