name: MLB Full Daily Pipeline

on:
  workflow_dispatch:

jobs:
  run-full-mlb-pipeline:
    runs-on: ubuntu-latest

    env:
      AWS_REGION: us-west-2
      S3_BUCKET: fantasy-sports-csvs
      BASEBALL_DIR: baseball

    steps:
      - name: Checkout repo
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: pip install boto3 pytz

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Download raw files from S3
        run: |
          aws s3 cp s3://$S3_BUCKET/$BASEBALL_DIR/betting/ ./betting/ --recursive
          aws s3 cp s3://$S3_BUCKET/$BASEBALL_DIR/weather/ ./weather/ --recursive
          aws s3 cp s3://$S3_BUCKET/$BASEBALL_DIR/rosters/ ./rosters/ --recursive
          aws s3 cp s3://$S3_BUCKET/$BASEBALL_DIR/probablestarters/ ./probablestarters/ --recursive
          aws s3 cp s3://$S3_BUCKET/$BASEBALL_DIR/news/ ./news/ --recursive
          aws s3 cp s3://$S3_BUCKET/$BASEBALL_DIR/boxscores/ ./boxscores/ --recursive

      - name: Create output folders
        run: mkdir -p baseball/combined

      - name: Run combine script to generate structured file
        run: python mlb_combine_all_files.py

      - name: Verify combined files
        run: |
          echo "Listing combined folder:"
          ls -l baseball/combined

      - name: Download latest structured player file from S3
        run: |
          DATE=$(date -u +"%Y-%m-%d")
          aws s3 cp s3://$S3_BUCKET/$BASEBALL_DIR/combined/structured_players_${DATE}.json baseball/combined/structured_players_${DATE}.json

      - name: Run analyzer script to enhance structured file
        run: python player_stats_analyzer.py

      - name: Copy enhanced file to article generator directory
        run: |
          DATE=$(date -u +"%Y-%m-%d")
          echo "Copying enhanced_structured_players_${DATE}.json"
          ls -la baseball/combined/
          cp baseball/combined/enhanced_structured_players_${DATE}.json mlb_baseball_article_generator/

      - name: Run DFS article generator
        run: |
          DATE=$(date -u +"%Y-%m-%d")
          echo "Generating DFS article for ${DATE}"
          python mlb_baseball_article_generator/generate_dfs_article.py --date $DATE

      - name: Upload all generated files to S3
        run: aws s3 cp ./baseball/combined/ s3://$S3_BUCKET/$BASEBALL_DIR/combined/ --recursive
